{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch,math,sys\n",
    "\n",
    "#Unmodified from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "def conv1d(ni:int, no:int, ks:int=1, stride:int=1, padding:int=0, bias:bool=False):\n",
    "    \"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias: conv.bias.data.zero_()\n",
    "    return spectral_norm(conv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We compare two implementations of SimpleSelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have at their core this self-attention operation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex2png.com/output//latex_e06d8a3710c644867bc207268affb4d5.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is originally an input tensor of shape (input_channels, height , width) which gets reshaped to (input_channels, N) where N = height * width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W is a tensor of shape (input_channels, input_channels). W * x is implemented as a 1 * 1 convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show that order of operation matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleSelfAttention1 multiplies matrices in the naive order:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex2png.com/output//latex_0d9f4fa0f02db47f472dc4e681a8c54e.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSelfAttention1(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in:int, ks=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv1d(n_in, n_in, ks, padding=ks//2, bias=False)\n",
    "        self.gamma = nn.Parameter(tensor([0.]))       \n",
    "        self.n_in = n_in\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "    \n",
    "        size = x.size()            #(Minibatch, Channels, Height, Width)\n",
    "        x = x.view(*size[:2],-1)           #(Minibatch, Channels, N)\n",
    "        o = torch.bmm(x.permute(0,2,1).contiguous(),self.conv(x))           # x^T * (W * x)    \n",
    "        o = self.gamma * torch.bmm(x,o) + x\n",
    "\n",
    "\n",
    "        return o.view(*size).contiguous()    \n",
    "    \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While SimpleSelfAttention2 does it in a different order:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://latex2png.com/output//latex_68f9f369ddb38f790f1033f4c09a184c.png\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSelfAttention2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in:int, ks=1):#, n_out:int):\n",
    "        super().__init__()\n",
    "           \n",
    "        self.conv = conv1d(n_in, n_in, ks, padding=ks//2, bias=False)    \n",
    "        self.gamma = nn.Parameter(tensor([0.]))\n",
    "        self.n_in = n_in\n",
    "        \n",
    "    def forward(self,x):        \n",
    "                              \n",
    "        size = x.size()  \n",
    "        x = x.view(*size[:2],-1)   # (C,N)               \n",
    "        convx = self.conv(x)   # (C,C) * (C,N) = (C,N)   => O(NC^2)\n",
    "        xxT = torch.bmm(x,x.permute(0,2,1).contiguous())   # (C,N) * (N,C) = (C,C)   => O(NC^2)        \n",
    "        o = torch.bmm(xxT, convx)   # (C,C) * (C,N) = (C,N)   => O(NC^2)          \n",
    "        o = self.gamma * o + x\n",
    "        \n",
    "          \n",
    "        return o.view(*size).contiguous()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of computing the product of two rectangular matrices of shape (n,m) and (m.p) is O(nmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the operation in SimpleSelfAttention1 is O(NC^2 + CN^2) while for SimpleSelfAttention2 it is O(NC^2)\n",
    "Remember that N = height * width, so having complexity increase with N^2 is very undesirable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if this works in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 64\n",
    "x = torch.randn(64, n_in,32,32)  #minibatch,C,H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first check that the two modules have the same output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(sa1(x),sa2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the runtimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 ms ± 28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 ms ± 31.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what happens if we increase channel size by a factor of 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 1024\n",
    "x = torch.randn(64, n_in,32,32)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07 s ± 39.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 s ± 40.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleSelfAttention2 is more sensitive to channel size. Something to keep in mind if we work with high channel sizes with low input spatial dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens if we just double spatial dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to 64 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 64\n",
    "x = torch.randn(64, n_in,64,64)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32 s ± 49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 ms ± 22.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's double them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 64\n",
    "x = torch.randn(64, n_in,128,128)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.5 s ± 1.78 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 s ± 58.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleSelfAttention is much better at handling larger spatial dimensions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this compare to the original Self Attention layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original SelfAttention layer as currently implemented in fast.ai\n",
    "https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "\n",
    "This implementation is based on the SAGAN paper\n",
    "https://arxiv.org/abs/1805.08318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"Self attention layer for nd.\"\n",
    "    def __init__(self, n_channels:int):\n",
    "        super().__init__()\n",
    "        self.query = conv1d(n_channels, n_channels//8)\n",
    "        self.key   = conv1d(n_channels, n_channels//8)\n",
    "        self.value = conv1d(n_channels, n_channels)\n",
    "        self.gamma = nn.Parameter(tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Notation from https://arxiv.org/pdf/1805.08318.pdf\n",
    "        size = x.size()\n",
    "        x = x.view(*size[:2],-1)\n",
    "        f,g,h = self.query(x),self.key(x),self.value(x)\n",
    "        beta = F.softmax(torch.bmm(f.permute(0,2,1).contiguous(), g), dim=1)\n",
    "        o = self.gamma * torch.bmm(h, beta) + x\n",
    "        return o.view(*size).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem that we can use the same reordering trick, due to the presence of softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs from SelfAttention and SimpleSelfAttention won't match, but we can compare runtimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 32\n",
    "x = torch.randn(64, n_in,16,16)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)\n",
    "sa0 = SelfAttention(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 ms ± 35.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa0(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 6.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.9 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double image size\n",
    "n_in = 32\n",
    "x = torch.randn(64, n_in,32,32)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)\n",
    "sa0 = SelfAttention(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.85 s ± 206 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa0(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 ms ± 10.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ms ± 22.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double image size again\n",
    "n_in = 32\n",
    "x = torch.randn(64, n_in,64,64)  #minibatch,C,H,W\n",
    "sa1 = SimpleSelfAttention1(n_in)\n",
    "sa2 = SimpleSelfAttention2(n_in)\n",
    "sa0 = SelfAttention(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 9.91 s, total: 2min 50s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.5878e-01,  1.2338e+00,  5.2843e-01,  ..., -2.9998e-01,\n",
       "            7.1314e-01, -4.6787e-01],\n",
       "          [ 5.3816e-01,  1.2520e+00, -5.7126e-02,  ..., -7.3750e-01,\n",
       "           -2.7030e-01, -5.1272e-01],\n",
       "          [ 1.5741e+00,  7.8619e-01,  7.7834e-01,  ...,  1.0803e+00,\n",
       "            3.2582e-01,  4.1008e-01],\n",
       "          ...,\n",
       "          [ 2.6405e+00, -2.3683e+00,  3.3436e-01,  ...,  3.8543e-01,\n",
       "            1.0957e+00, -5.4066e-01],\n",
       "          [-1.4477e-01, -2.9981e-01, -7.0663e-01,  ..., -7.3166e-02,\n",
       "           -1.0477e+00,  1.4565e+00],\n",
       "          [-1.0083e+00,  6.1483e-01,  2.1860e-01,  ...,  1.2566e+00,\n",
       "           -3.4978e-01, -2.0957e+00]],\n",
       "\n",
       "         [[-8.5598e-01,  4.4064e-01,  1.0505e+00,  ...,  3.4780e-01,\n",
       "            1.2274e+00,  1.5416e-01],\n",
       "          [ 1.1609e-01,  8.6406e-01, -1.4297e+00,  ...,  9.5329e-01,\n",
       "           -1.5561e-01,  5.7680e-01],\n",
       "          [ 1.4711e+00,  1.6361e+00,  1.0770e+00,  ..., -1.3232e+00,\n",
       "           -4.5743e-01,  2.2284e+00],\n",
       "          ...,\n",
       "          [-8.3383e-01,  1.6097e+00, -2.1431e-01,  ...,  1.0455e+00,\n",
       "            1.9279e-01,  1.3844e+00],\n",
       "          [-9.5105e-02,  1.7130e+00, -5.1270e-01,  ..., -1.9409e+00,\n",
       "            1.0471e+00,  1.3851e-01],\n",
       "          [-3.2816e+00,  1.3750e+00, -2.1375e-01,  ...,  2.3182e-01,\n",
       "            8.8326e-01,  8.4310e-01]],\n",
       "\n",
       "         [[ 5.6171e-01, -1.8656e-01, -5.1153e-01,  ...,  8.5278e-01,\n",
       "           -2.2674e+00, -1.2619e-01],\n",
       "          [ 2.1387e-01,  9.4631e-01, -4.7938e-01,  ...,  2.7920e+00,\n",
       "            1.2741e+00, -1.1181e+00],\n",
       "          [ 3.6035e-01, -6.4955e-02,  1.2871e-01,  ..., -1.2838e+00,\n",
       "            1.2180e+00, -1.1789e-01],\n",
       "          ...,\n",
       "          [-7.7448e-01,  4.6956e-01, -4.3997e-01,  ..., -2.9887e-01,\n",
       "            9.6921e-01, -1.2878e+00],\n",
       "          [-1.6019e+00, -7.4791e-01,  3.3058e-02,  ...,  4.8200e-01,\n",
       "           -2.2436e-02,  4.6782e-01],\n",
       "          [ 1.1205e+00,  1.2985e+00,  1.2169e+00,  ...,  1.1330e-01,\n",
       "           -2.9893e+00,  1.0721e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4293e+00, -2.1578e+00, -1.3134e-01,  ..., -7.5526e-01,\n",
       "           -4.4836e-01, -2.2197e+00],\n",
       "          [ 4.2887e-01, -1.1830e+00,  2.9100e-01,  ..., -1.3157e-01,\n",
       "            1.2162e+00,  7.9392e-01],\n",
       "          [ 2.6740e-01,  4.9072e-01,  1.3662e+00,  ..., -4.1877e-01,\n",
       "           -4.6252e-01, -9.0797e-01],\n",
       "          ...,\n",
       "          [-1.8084e-01, -2.2511e-01, -1.0451e+00,  ...,  1.1398e+00,\n",
       "           -2.8080e-01,  9.2534e-01],\n",
       "          [-3.8362e-01, -6.9150e-01,  1.1430e+00,  ..., -1.4709e+00,\n",
       "           -1.8813e+00,  1.1947e+00],\n",
       "          [ 6.2051e-01,  1.9307e-01, -1.2832e+00,  ..., -2.0257e-01,\n",
       "            2.8087e-01,  5.3759e-01]],\n",
       "\n",
       "         [[-5.3331e-01, -4.9562e-01,  1.7837e+00,  ..., -2.8646e-01,\n",
       "           -1.3528e-01, -1.0329e+00],\n",
       "          [-2.1688e-01,  5.7731e-02,  1.9444e+00,  ...,  1.7186e-01,\n",
       "           -1.4441e-02, -3.5573e-01],\n",
       "          [ 5.0738e-01, -1.1758e-01, -3.1396e-01,  ...,  8.7662e-01,\n",
       "           -1.0966e+00, -7.3998e-01],\n",
       "          ...,\n",
       "          [ 8.0984e-01, -7.5560e-01, -1.4400e+00,  ...,  6.4789e-01,\n",
       "            1.2396e-01,  5.8653e-01],\n",
       "          [ 4.1938e-01, -5.8374e-02,  2.0724e+00,  ..., -7.1865e-01,\n",
       "           -2.8971e-01, -4.3057e-01],\n",
       "          [ 7.6506e-01, -3.2942e-01,  6.5101e-01,  ...,  2.3910e+00,\n",
       "           -1.8732e-01,  1.4497e+00]],\n",
       "\n",
       "         [[ 1.8705e-01,  2.3758e-01, -9.5787e-01,  ...,  1.1337e-01,\n",
       "           -9.4196e-01, -1.9520e+00],\n",
       "          [-2.0028e-01, -3.6852e-01, -1.7661e+00,  ..., -1.5396e+00,\n",
       "           -6.6007e-01, -7.9840e-01],\n",
       "          [ 9.7515e-01,  7.4019e-01, -4.7309e-01,  ..., -4.6550e-01,\n",
       "            4.8856e-02,  1.0041e+00],\n",
       "          ...,\n",
       "          [ 3.7056e-01,  8.2592e-01, -3.9844e-01,  ..., -1.1388e+00,\n",
       "           -1.2862e+00, -4.4092e-01],\n",
       "          [-9.3515e-01,  7.4389e-01, -7.6159e-01,  ...,  4.2287e-01,\n",
       "            5.9751e-01, -2.6581e-01],\n",
       "          [-6.9547e-01,  9.4948e-01, -1.3946e+00,  ..., -1.3635e+00,\n",
       "           -8.4177e-02,  3.4249e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2154e+00, -7.4164e-01,  1.4756e+00,  ..., -1.0536e+00,\n",
       "           -6.3735e-02, -3.0991e-01],\n",
       "          [ 1.2250e+00,  1.1730e-01, -6.9942e-01,  ...,  8.6474e-01,\n",
       "           -4.8445e-01,  5.2179e-01],\n",
       "          [ 1.5105e+00,  1.5281e-02,  5.5283e-01,  ...,  1.2608e+00,\n",
       "            1.9776e+00, -1.3065e+00],\n",
       "          ...,\n",
       "          [-6.2764e-01, -7.5969e-01,  1.8380e+00,  ..., -1.0404e+00,\n",
       "            3.1686e-01,  1.0067e-01],\n",
       "          [-1.0166e+00, -2.3625e+00,  7.0673e-01,  ...,  1.6764e+00,\n",
       "            1.9065e+00, -6.5062e-02],\n",
       "          [-7.8073e-01, -1.2108e+00, -6.0244e-01,  ..., -7.9432e-01,\n",
       "            3.4349e-02,  1.6257e+00]],\n",
       "\n",
       "         [[-9.1193e-01,  8.9882e-02, -1.1820e+00,  ...,  1.6026e+00,\n",
       "            1.1564e+00, -2.4195e-01],\n",
       "          [ 1.1347e+00,  1.1992e+00,  5.3052e-01,  ..., -1.6758e+00,\n",
       "            3.0877e-01, -2.1711e-01],\n",
       "          [ 2.4803e-01,  1.4037e+00,  1.8676e+00,  ..., -3.0054e-01,\n",
       "            1.6730e+00, -2.8228e-01],\n",
       "          ...,\n",
       "          [ 9.3293e-01,  1.1716e+00,  2.3420e+00,  ...,  1.2055e+00,\n",
       "            6.9776e-01, -7.3770e-01],\n",
       "          [ 1.3754e-01,  3.2932e-01, -1.5820e+00,  ...,  1.0585e+00,\n",
       "            4.3001e-01,  2.8167e-01],\n",
       "          [ 3.4374e-01, -8.7395e-01, -4.3824e-01,  ...,  1.2958e+00,\n",
       "            3.6642e-01,  4.1438e-01]],\n",
       "\n",
       "         [[ 4.8778e-01,  6.0229e-01, -1.8232e-01,  ..., -1.2310e+00,\n",
       "           -1.6323e+00, -8.9462e-01],\n",
       "          [-3.2784e-02, -1.7304e+00, -6.0484e-01,  ...,  9.1862e-02,\n",
       "            3.1920e-01,  2.1240e+00],\n",
       "          [ 3.2554e-01,  1.7813e+00,  2.9077e-01,  ..., -8.8244e-01,\n",
       "            1.2172e-01, -1.7886e-01],\n",
       "          ...,\n",
       "          [-7.4258e-01,  1.4608e+00,  2.0071e+00,  ..., -9.4485e-01,\n",
       "           -5.8849e-01,  2.6520e-01],\n",
       "          [-2.4124e+00, -3.7749e-03,  1.5589e-01,  ...,  4.7882e-01,\n",
       "           -9.4841e-02, -5.3867e-01],\n",
       "          [ 8.9938e-02,  5.5276e-01,  1.5448e+00,  ..., -1.2979e-01,\n",
       "           -1.8041e+00, -5.6367e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1000e+00, -1.3052e+00, -8.1753e-01,  ...,  1.0896e+00,\n",
       "            3.8840e-01,  4.6778e-01],\n",
       "          [-1.2005e+00,  9.8054e-01,  7.7243e-01,  ..., -5.5424e-01,\n",
       "           -1.6592e-01,  1.3446e+00],\n",
       "          [ 2.1038e+00, -8.3515e-01, -1.8834e-01,  ...,  5.6855e-01,\n",
       "            8.7589e-01, -1.0462e-01],\n",
       "          ...,\n",
       "          [-5.8939e-01, -2.1911e-02,  4.1537e-01,  ..., -1.5968e+00,\n",
       "            1.4717e+00, -4.5161e-02],\n",
       "          [-7.2363e-01,  7.3829e-01, -5.5366e-01,  ...,  1.0947e-01,\n",
       "            1.0485e+00, -1.3996e+00],\n",
       "          [-9.4445e-01, -6.5667e-01,  9.1526e-01,  ..., -6.0324e-01,\n",
       "            4.3761e-01,  3.2016e-02]],\n",
       "\n",
       "         [[ 1.5737e+00,  2.3509e+00, -8.5722e-01,  ...,  2.9848e-01,\n",
       "           -3.6078e-01, -2.1792e+00],\n",
       "          [-2.1180e-01,  1.9278e-01,  5.3472e-01,  ...,  8.2784e-01,\n",
       "           -7.8065e-01,  3.3999e-01],\n",
       "          [-9.1739e-01, -2.9155e-01, -1.3534e+00,  ...,  3.1496e-01,\n",
       "           -4.1462e-02,  4.4189e-01],\n",
       "          ...,\n",
       "          [ 8.6646e-01, -7.1145e-01,  4.7330e-01,  ...,  1.1212e-01,\n",
       "           -6.3504e-01, -9.0294e-02],\n",
       "          [-1.2840e+00, -3.5863e-01, -4.7026e-01,  ..., -1.1110e-01,\n",
       "           -1.2945e+00,  2.1510e+00],\n",
       "          [-2.3464e+00, -3.2169e-01,  1.2459e+00,  ..., -2.5168e-01,\n",
       "           -4.5719e-01, -1.7654e-01]],\n",
       "\n",
       "         [[ 9.6283e-01,  1.1409e+00, -1.3159e+00,  ..., -3.3695e-01,\n",
       "           -3.4850e-01, -1.3688e+00],\n",
       "          [ 1.7158e-01,  7.9958e-01,  1.8189e+00,  ..., -8.0641e-01,\n",
       "           -1.9681e+00,  2.6623e-01],\n",
       "          [ 8.8200e-01, -1.6632e-01, -6.7843e-01,  ..., -9.9506e-01,\n",
       "           -2.3324e+00,  1.6994e+00],\n",
       "          ...,\n",
       "          [ 4.8355e-02, -5.5759e-01,  2.4170e-01,  ..., -9.2803e-01,\n",
       "            7.4282e-01, -1.5672e+00],\n",
       "          [-3.2099e-01,  1.7929e-01, -2.6457e+00,  ...,  1.7218e+00,\n",
       "            6.4938e-01,  9.1615e-01],\n",
       "          [-1.1064e+00, -5.5665e-01,  8.7013e-01,  ..., -6.4613e-01,\n",
       "           -2.2592e+00,  4.8353e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1031e+00,  4.0425e-01, -1.3352e-01,  ..., -1.1812e+00,\n",
       "           -2.3036e-01, -1.5331e-03],\n",
       "          [ 2.4963e-01,  8.6197e-01, -1.2596e+00,  ...,  3.6399e-01,\n",
       "            4.3547e-01, -4.7188e-01],\n",
       "          [-1.0047e+00,  9.0791e-01,  8.7148e-01,  ...,  8.1897e-01,\n",
       "            1.3544e+00, -2.0417e+00],\n",
       "          ...,\n",
       "          [-2.5486e+00,  1.1093e+00, -1.4432e+00,  ...,  2.8798e+00,\n",
       "           -2.5564e+00, -2.2867e-01],\n",
       "          [ 5.2608e-01, -1.0551e+00,  1.2218e+00,  ...,  1.5380e+00,\n",
       "           -1.5143e+00,  1.1369e+00],\n",
       "          [-8.4161e-01,  1.5424e-01,  1.5905e+00,  ..., -3.3543e-01,\n",
       "            2.6649e-01,  7.7433e-01]],\n",
       "\n",
       "         [[ 7.3464e-01,  2.3182e-02,  5.5915e-01,  ..., -7.7351e-01,\n",
       "            4.4103e-01, -1.9972e-01],\n",
       "          [ 9.7420e-01, -6.5814e-01, -5.9284e-01,  ..., -4.1397e-01,\n",
       "           -2.2707e+00, -2.2411e-01],\n",
       "          [ 1.6986e+00, -3.5148e-01, -6.9570e-01,  ..., -2.5088e-01,\n",
       "           -5.4940e-01, -6.3205e-01],\n",
       "          ...,\n",
       "          [ 1.3674e+00,  8.5961e-01,  1.0792e-01,  ...,  1.0765e+00,\n",
       "            9.7682e-02,  2.2393e+00],\n",
       "          [ 4.4959e-01,  1.4900e+00,  2.3937e+00,  ..., -1.6830e+00,\n",
       "           -7.1152e-01, -1.2533e+00],\n",
       "          [-1.0713e+00,  2.2913e+00,  2.2402e-01,  ..., -5.2888e-01,\n",
       "            2.4474e+00,  2.3687e-02]],\n",
       "\n",
       "         [[-7.8381e-01, -2.6025e+00, -8.8730e-01,  ..., -1.0404e-03,\n",
       "           -1.2833e+00, -7.1515e-01],\n",
       "          [-4.8048e-01,  1.0015e+00, -1.0192e+00,  ...,  1.3122e-01,\n",
       "            1.4450e+00, -7.5521e-01],\n",
       "          [-3.6298e-01, -1.9290e+00,  5.1660e-02,  ..., -1.5389e+00,\n",
       "           -1.0917e+00, -5.3875e-01],\n",
       "          ...,\n",
       "          [-4.3967e-01, -1.5303e-01, -2.8450e-01,  ...,  2.6088e-01,\n",
       "            1.5687e-01, -7.0465e-01],\n",
       "          [-2.0355e+00, -1.1965e+00, -1.9107e+00,  ...,  1.4877e+00,\n",
       "           -2.4546e-01, -1.9611e-01],\n",
       "          [ 3.1995e-01,  1.4263e+00,  1.3245e+00,  ...,  2.2202e+00,\n",
       "           -8.0757e-01, -2.3186e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3343e-01,  4.5987e-01, -8.2119e-01,  ..., -1.5780e+00,\n",
       "            7.3759e-01, -6.1095e-01],\n",
       "          [-5.6319e-01, -6.8396e-01, -4.4311e-01,  ..., -2.4700e-01,\n",
       "            8.4167e-01, -1.4236e+00],\n",
       "          [ 8.0429e-01, -5.5432e-01,  1.8192e-02,  ...,  5.9873e-01,\n",
       "            6.0060e-01, -6.3959e-01],\n",
       "          ...,\n",
       "          [-1.6666e-01, -1.6018e-01, -6.1048e-01,  ...,  7.8136e-01,\n",
       "            3.6611e-02,  1.1171e+00],\n",
       "          [ 8.3839e-01, -2.3740e-01, -8.6393e-01,  ...,  4.8336e-01,\n",
       "            3.8151e-01,  2.1655e+00],\n",
       "          [ 2.2780e-01, -2.9599e+00,  1.1950e+00,  ...,  9.2909e-01,\n",
       "           -2.0706e-01,  1.5007e+00]],\n",
       "\n",
       "         [[ 4.3072e-01,  1.5475e+00,  6.7444e-01,  ..., -1.3720e+00,\n",
       "           -5.3210e-01,  1.6079e-01],\n",
       "          [-1.7834e+00, -1.0689e+00, -4.7091e-01,  ..., -1.7415e-01,\n",
       "           -9.0041e-01, -4.4552e-01],\n",
       "          [-9.4973e-02,  8.1383e-01,  1.6748e+00,  ...,  8.4746e-01,\n",
       "           -1.2982e+00,  9.1504e-01],\n",
       "          ...,\n",
       "          [ 4.3775e-01,  5.9013e-01, -3.5665e-01,  ...,  3.2808e-01,\n",
       "            4.2788e-01, -1.6684e+00],\n",
       "          [ 6.1129e-01, -8.9117e-01, -1.1211e+00,  ..., -5.3912e-01,\n",
       "           -1.9407e-01,  8.5915e-01],\n",
       "          [-1.5054e+00,  1.8257e+00, -8.9435e-01,  ...,  1.2669e-01,\n",
       "           -6.3389e-01,  1.3356e+00]],\n",
       "\n",
       "         [[-6.2267e-01, -1.3662e-01,  6.6594e-01,  ...,  2.2289e+00,\n",
       "            7.2990e-02,  5.0015e-01],\n",
       "          [ 1.3839e+00,  8.3064e-01, -8.6645e-01,  ...,  1.8323e+00,\n",
       "            1.2651e-01, -3.1866e-01],\n",
       "          [-2.1641e-01,  8.6679e-01,  1.9400e+00,  ...,  6.3276e-01,\n",
       "           -2.2129e+00, -1.3423e+00],\n",
       "          ...,\n",
       "          [ 1.1000e+00,  2.7832e-01,  1.3310e+00,  ..., -1.4921e-01,\n",
       "           -1.8145e+00,  1.1504e+00],\n",
       "          [ 7.3933e-01,  2.9995e-01,  9.4385e-01,  ..., -1.2213e-02,\n",
       "           -6.2759e-01, -1.2349e+00],\n",
       "          [ 1.8549e-01,  2.4233e-01,  1.6327e-02,  ...,  6.2604e-01,\n",
       "            1.1444e-01, -1.8051e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 7.2922e-02,  3.9620e-01, -9.5128e-01,  ..., -7.7325e-01,\n",
       "           -1.7970e+00,  3.0334e-02],\n",
       "          [-2.7727e-01, -3.3648e-01,  1.0795e+00,  ..., -1.8488e+00,\n",
       "            5.5977e-01, -9.8492e-02],\n",
       "          [ 2.8736e-01, -1.0314e+00, -1.8016e+00,  ...,  3.5137e-01,\n",
       "            1.9380e+00,  5.9235e-01],\n",
       "          ...,\n",
       "          [-6.0140e-01, -1.0251e+00,  1.1087e+00,  ...,  9.9779e-01,\n",
       "            3.7008e-01, -3.0553e-01],\n",
       "          [-3.9076e-01,  1.4961e-01,  5.0173e-01,  ...,  2.0921e-01,\n",
       "           -6.1516e-01, -3.4909e-01],\n",
       "          [ 1.2341e+00, -1.3422e-01, -1.4984e+00,  ...,  2.5049e-01,\n",
       "            2.0339e+00, -3.7075e-01]],\n",
       "\n",
       "         [[-3.0204e-02,  1.9822e-01,  2.8581e-01,  ...,  6.5470e-01,\n",
       "           -1.3715e+00, -1.5627e+00],\n",
       "          [-1.1013e+00,  4.5097e-02, -3.5355e-01,  ..., -1.1591e+00,\n",
       "           -8.2365e-01, -2.9178e+00],\n",
       "          [-1.0608e+00, -1.0033e+00, -2.3004e+00,  ...,  1.4033e+00,\n",
       "            2.8989e-01,  1.2650e+00],\n",
       "          ...,\n",
       "          [ 6.7092e-01, -1.6302e-01, -4.6674e-01,  ...,  3.2790e-01,\n",
       "            7.9630e-01,  1.6109e-01],\n",
       "          [-7.2111e-01,  1.4304e+00,  1.9368e-01,  ...,  1.0497e+00,\n",
       "           -1.2065e-01, -9.8951e-01],\n",
       "          [-9.7553e-01,  4.0237e-02, -1.0291e+00,  ..., -9.3905e-01,\n",
       "            7.4281e-01,  1.7294e+00]],\n",
       "\n",
       "         [[-1.7430e+00, -7.9806e-01,  7.8677e-01,  ..., -2.7215e-01,\n",
       "           -1.5145e+00,  5.6702e-01],\n",
       "          [-2.0414e-01,  1.2317e+00,  3.4571e-01,  ...,  1.4106e-01,\n",
       "            1.8174e+00,  3.4313e-02],\n",
       "          [ 1.1448e-01,  7.7387e-01, -2.4339e+00,  ..., -3.6487e-01,\n",
       "            3.7814e-01, -1.0466e+00],\n",
       "          ...,\n",
       "          [ 1.0191e+00,  5.4538e-02,  5.5459e-01,  ...,  3.0388e-01,\n",
       "            1.6532e+00, -1.6008e+00],\n",
       "          [ 9.7606e-01,  4.7701e-01, -1.4179e+00,  ...,  1.9467e+00,\n",
       "            7.9977e-01, -7.1341e-01],\n",
       "          [ 8.6197e-01,  1.8566e-01, -1.6038e+00,  ..., -2.7128e-01,\n",
       "            2.4174e+00,  3.5659e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9130e+00, -7.3110e-01,  3.2848e-01,  ..., -3.3707e-01,\n",
       "            1.2328e-01, -6.1602e-01],\n",
       "          [-1.2633e+00,  1.8931e+00,  5.7780e-01,  ..., -1.3133e-01,\n",
       "           -5.8761e-02, -7.3085e-01],\n",
       "          [-2.1239e+00, -1.0355e+00, -5.2107e-01,  ..., -1.5517e+00,\n",
       "           -7.5701e-01,  6.0573e-01],\n",
       "          ...,\n",
       "          [-2.3069e-01,  6.3023e-02,  1.5296e-01,  ...,  4.0458e-01,\n",
       "            1.0633e-01,  9.7396e-02],\n",
       "          [ 3.9505e-01,  6.4875e-01, -3.3975e-01,  ..., -9.1754e-01,\n",
       "            5.6406e-01,  3.2958e-01],\n",
       "          [-6.9629e-01,  1.8879e-01, -4.6368e-01,  ...,  4.4803e-01,\n",
       "            1.7666e+00,  1.1508e+00]],\n",
       "\n",
       "         [[-4.7286e-01,  2.1841e-01, -7.1991e-02,  ...,  1.0195e+00,\n",
       "            7.5265e-01,  1.8178e+00],\n",
       "          [-6.4312e-01,  5.4425e-01,  7.1506e-01,  ...,  6.9796e-01,\n",
       "            1.1270e+00, -1.4247e+00],\n",
       "          [ 4.4299e-01, -6.0545e-01, -2.0826e-01,  ..., -1.2055e+00,\n",
       "            1.0440e+00, -8.2765e-01],\n",
       "          ...,\n",
       "          [ 2.7365e-01, -1.9765e+00, -1.8758e-01,  ..., -1.7819e-01,\n",
       "           -1.1039e+00,  1.1567e+00],\n",
       "          [-9.2478e-01, -1.9637e+00, -5.5460e-01,  ..., -6.8389e-01,\n",
       "           -1.1650e+00, -9.0535e-01],\n",
       "          [-2.3660e-01,  1.0965e+00, -1.0116e+00,  ...,  2.3477e-01,\n",
       "           -9.4984e-01, -8.2540e-01]],\n",
       "\n",
       "         [[ 5.3224e-01,  8.7361e-01,  8.3631e-01,  ...,  7.8797e-01,\n",
       "            1.2778e+00, -7.2099e-01],\n",
       "          [-8.9718e-01, -1.0549e+00,  1.4306e+00,  ...,  2.0972e-01,\n",
       "           -7.6540e-02,  1.7570e-01],\n",
       "          [-1.7013e+00, -4.5525e-01, -1.6869e+00,  ...,  8.2944e-01,\n",
       "           -1.8294e+00,  1.8358e+00],\n",
       "          ...,\n",
       "          [ 1.2425e+00,  3.6100e-01, -7.1976e-01,  ..., -5.4901e-02,\n",
       "            1.6331e+00, -1.1761e+00],\n",
       "          [-1.0439e+00, -1.2407e+00,  7.0101e-01,  ...,  4.9524e-01,\n",
       "            2.9904e-01, -1.5582e+00],\n",
       "          [-1.3749e+00, -2.1765e-01,  3.3748e-01,  ...,  8.1204e-01,\n",
       "           -1.3948e+00,  5.4665e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.8182e-02,  3.0047e-01,  1.1911e+00,  ..., -1.7046e-01,\n",
       "            7.4566e-01,  8.8598e-01],\n",
       "          [-1.8543e+00,  1.5940e+00,  1.0893e-02,  ...,  2.0893e-01,\n",
       "           -3.0059e-01, -2.7630e+00],\n",
       "          [ 4.1807e-01,  2.3250e-01, -6.1423e-01,  ..., -1.8982e-01,\n",
       "            2.6667e-01,  8.3266e-02],\n",
       "          ...,\n",
       "          [ 2.6186e-01, -1.9274e+00,  1.9191e+00,  ...,  9.7867e-01,\n",
       "           -2.7542e-02, -2.4884e-01],\n",
       "          [ 8.2473e-01, -2.2732e+00, -7.2797e-01,  ..., -4.4699e-01,\n",
       "            7.2557e-01,  9.9060e-01],\n",
       "          [-6.7443e-01,  5.4649e-01,  3.6239e-02,  ..., -6.6717e-01,\n",
       "           -2.7164e-01,  1.3730e+00]],\n",
       "\n",
       "         [[ 4.0962e-01, -2.9156e-01, -4.6114e-01,  ..., -3.3454e-01,\n",
       "            1.8154e+00, -7.0231e-01],\n",
       "          [-1.5548e+00,  5.2977e-01,  7.8195e-01,  ..., -1.7118e+00,\n",
       "           -3.7877e-01,  3.2033e-01],\n",
       "          [ 1.1721e+00, -1.0282e+00,  1.0633e+00,  ...,  1.2755e+00,\n",
       "            5.8702e-02,  1.2327e+00],\n",
       "          ...,\n",
       "          [-1.4163e+00, -5.8060e-01,  7.4265e-01,  ...,  6.2367e-01,\n",
       "            3.0014e-01,  5.0375e-01],\n",
       "          [ 5.6351e-01, -1.4710e+00,  1.4928e+00,  ...,  3.4337e-01,\n",
       "           -1.2354e+00, -5.2750e-01],\n",
       "          [ 5.2198e-01,  1.1291e+00,  7.6595e-01,  ...,  2.1727e-01,\n",
       "            7.9493e-01, -1.4323e-01]],\n",
       "\n",
       "         [[-1.5513e+00, -2.3878e-01, -8.2569e-01,  ...,  1.2627e+00,\n",
       "            1.3311e-02, -9.3112e-01],\n",
       "          [-1.3588e-01,  1.4025e-01,  5.3310e-01,  ..., -1.1720e+00,\n",
       "            1.9679e+00,  6.3172e-02],\n",
       "          [-1.3562e+00,  6.2509e-01,  1.1642e+00,  ..., -1.7152e-01,\n",
       "            4.8028e-01,  1.4251e+00],\n",
       "          ...,\n",
       "          [-8.2791e-01, -1.0362e+00, -1.1039e-01,  ..., -1.2881e+00,\n",
       "           -1.5152e+00, -1.1765e+00],\n",
       "          [ 2.5235e-01,  8.7841e-01, -2.0490e-01,  ...,  1.0541e-01,\n",
       "           -8.0544e-01,  9.7736e-01],\n",
       "          [-1.1507e-01, -2.6981e+00,  1.2120e-01,  ...,  1.3572e+00,\n",
       "           -1.0661e+00, -1.5577e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7306e+00, -1.8382e+00,  5.2291e-01,  ..., -1.6965e+00,\n",
       "           -1.0603e+00, -4.4217e-01],\n",
       "          [-1.3345e+00, -5.2280e-01,  7.5762e-01,  ..., -1.6727e+00,\n",
       "            3.6564e-01,  2.2434e-02],\n",
       "          [-1.5512e-01,  7.8259e-01, -4.9109e-01,  ..., -8.5659e-01,\n",
       "            7.8690e-01, -3.0812e-01],\n",
       "          ...,\n",
       "          [ 5.8776e-01,  5.3267e-01, -9.9658e-01,  ...,  3.2494e-01,\n",
       "            1.1210e+00,  2.0573e+00],\n",
       "          [ 5.3609e-01,  5.5819e-01, -6.5650e-01,  ..., -4.0156e-01,\n",
       "           -4.0865e-01, -2.0288e+00],\n",
       "          [-8.8009e-01, -7.8829e-01,  1.0216e+00,  ..., -1.0772e-01,\n",
       "            3.3499e-01, -2.0116e+00]],\n",
       "\n",
       "         [[ 1.3106e+00,  8.6757e-01, -2.3625e-01,  ..., -3.8182e-01,\n",
       "           -8.4961e-01,  6.4967e-01],\n",
       "          [-1.2757e+00,  4.9288e-01,  3.2936e-01,  ...,  1.1319e+00,\n",
       "           -8.6022e-01,  9.3830e-01],\n",
       "          [-1.5993e-01, -8.5855e-01, -4.3434e-01,  ..., -9.1593e-02,\n",
       "            1.7436e-01,  2.5347e-01],\n",
       "          ...,\n",
       "          [ 5.1408e-01,  5.7738e-01,  1.9653e+00,  ...,  2.0975e-01,\n",
       "            2.9560e-01,  8.2121e-02],\n",
       "          [-1.5984e+00, -1.0262e+00, -4.8105e-01,  ...,  1.2855e+00,\n",
       "           -6.0929e-02, -1.3222e+00],\n",
       "          [ 9.9718e-01, -1.5297e+00, -9.5831e-01,  ..., -1.4960e+00,\n",
       "           -1.4392e+00,  6.1760e-01]],\n",
       "\n",
       "         [[ 9.8730e-01, -1.8920e-02, -5.0954e-01,  ...,  5.4647e-01,\n",
       "            1.4913e+00, -3.0940e-01],\n",
       "          [-9.9532e-01,  2.6403e+00,  1.1583e+00,  ...,  2.7875e-01,\n",
       "           -3.0952e-01,  8.4475e-01],\n",
       "          [-3.7538e-01,  1.2580e+00,  8.3554e-01,  ...,  1.7080e-01,\n",
       "            9.0588e-01, -1.0954e+00],\n",
       "          ...,\n",
       "          [ 5.0919e-01,  4.6538e-01,  1.6045e+00,  ...,  1.0383e+00,\n",
       "           -4.7876e-01,  1.3631e+00],\n",
       "          [ 4.0916e-01,  1.9137e+00,  1.8695e+00,  ..., -1.0202e+00,\n",
       "           -9.2704e-01,  4.3715e-01],\n",
       "          [ 4.3655e-01,  5.1219e-01, -1.2418e+00,  ..., -4.5693e-01,\n",
       "           -2.9246e-01, -4.4391e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.2962e-01,  1.8331e-01, -5.9005e-01,  ...,  8.1933e-01,\n",
       "           -2.0974e-01,  2.4981e-01],\n",
       "          [-2.4379e-01,  6.3383e-01, -4.1205e-01,  ...,  1.6134e+00,\n",
       "           -3.1842e-01, -2.0796e+00],\n",
       "          [ 1.9225e+00, -1.2998e+00, -1.4630e-01,  ..., -2.7077e-01,\n",
       "            2.4665e-01, -1.3408e-01],\n",
       "          ...,\n",
       "          [ 2.1386e+00,  4.1493e-01, -8.5951e-01,  ..., -1.5186e+00,\n",
       "            7.6123e-01, -3.7178e-01],\n",
       "          [-4.0491e-01, -2.3512e-01,  3.5099e-01,  ...,  5.6265e-01,\n",
       "            1.0006e+00, -1.5382e-01],\n",
       "          [-2.1462e-03, -1.1179e+00,  3.1609e-01,  ..., -3.6008e-01,\n",
       "           -2.2915e+00, -1.1049e+00]],\n",
       "\n",
       "         [[-1.7301e-01,  2.7949e-02, -1.7052e+00,  ..., -1.9189e+00,\n",
       "           -8.9524e-01,  1.8840e-01],\n",
       "          [ 1.3199e+00, -1.1183e+00, -1.3875e+00,  ..., -5.9682e-01,\n",
       "            4.2873e-01, -1.5269e+00],\n",
       "          [-6.8872e-01, -3.9753e-01,  1.7827e-01,  ..., -1.0471e+00,\n",
       "           -2.3874e-01, -1.2043e+00],\n",
       "          ...,\n",
       "          [ 1.0401e+00, -1.2045e+00, -5.0256e-01,  ..., -1.5641e-01,\n",
       "            1.0799e+00, -5.4025e-01],\n",
       "          [-6.2251e-01, -7.9759e-01, -1.8121e+00,  ...,  9.2351e-01,\n",
       "           -1.4732e+00, -7.3064e-02],\n",
       "          [-8.9536e-02, -1.0774e+00,  8.5924e-01,  ...,  2.5307e-01,\n",
       "           -1.4913e-01, -3.3883e-01]],\n",
       "\n",
       "         [[ 3.7701e-01,  3.8087e-01, -1.5530e+00,  ...,  1.6951e+00,\n",
       "            1.9671e-01, -9.0575e-01],\n",
       "          [-9.5321e-01,  4.6579e-01, -2.4798e-01,  ..., -3.1580e-01,\n",
       "            4.8608e-01,  1.5064e-01],\n",
       "          [-5.2138e-01,  1.6885e+00, -6.4376e-01,  ...,  7.1368e-01,\n",
       "           -8.5889e-02,  2.0714e-01],\n",
       "          ...,\n",
       "          [-1.8185e+00,  6.9944e-01, -1.5856e+00,  ...,  6.9540e-01,\n",
       "           -1.0517e+00,  3.4580e-01],\n",
       "          [ 1.9574e+00, -1.8675e+00, -2.4400e-01,  ..., -1.0019e+00,\n",
       "           -6.4951e-01,  9.9601e-01],\n",
       "          [ 5.3495e-02, -1.0371e+00, -1.2820e-01,  ..., -3.7725e-01,\n",
       "            9.1528e-01, -2.3477e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9068e-01,  6.0675e-01, -3.0584e-01,  ...,  6.7884e-01,\n",
       "           -2.0476e+00,  2.5076e+00],\n",
       "          [-8.0078e-01, -1.8461e+00,  1.7263e+00,  ..., -1.1254e-01,\n",
       "           -1.7464e+00, -1.0289e-01],\n",
       "          [-7.7365e-02,  9.0256e-02,  7.8842e-01,  ..., -4.4494e-01,\n",
       "            3.4405e+00, -2.7145e-01],\n",
       "          ...,\n",
       "          [-7.4008e-01,  1.9343e+00,  2.6505e-01,  ..., -7.6577e-01,\n",
       "            1.0355e+00,  6.1773e-01],\n",
       "          [ 2.2508e-01, -8.7751e-03,  1.9407e-01,  ...,  5.8049e-01,\n",
       "            5.0085e-01, -1.3381e+00],\n",
       "          [-7.4951e-03,  4.9267e-02,  1.4746e-01,  ..., -5.4135e-02,\n",
       "           -2.2475e-01,  7.1728e-01]],\n",
       "\n",
       "         [[ 9.1588e-01,  4.1774e-01,  4.1343e-01,  ...,  4.8681e-01,\n",
       "           -3.6323e-01,  1.0069e+00],\n",
       "          [ 1.5249e+00, -5.3520e-01,  9.5574e-01,  ...,  1.0538e-01,\n",
       "            1.5364e+00, -8.1441e-01],\n",
       "          [-1.6619e-01, -1.5291e-01, -2.2119e-01,  ...,  4.1690e-01,\n",
       "           -2.0151e+00,  1.6277e+00],\n",
       "          ...,\n",
       "          [-2.0259e+00, -1.3030e+00, -3.9875e-02,  ...,  8.9527e-01,\n",
       "            1.8258e+00,  9.3971e-01],\n",
       "          [-9.2753e-01,  1.6784e+00,  1.4851e+00,  ..., -1.5261e+00,\n",
       "            7.9198e-01, -1.6004e-01],\n",
       "          [-7.1318e-01,  1.0909e-01, -3.1491e-01,  ...,  1.6622e+00,\n",
       "           -5.5245e-01,  1.7508e+00]],\n",
       "\n",
       "         [[ 9.5691e-01,  7.2638e-01,  2.1914e+00,  ..., -8.0986e-01,\n",
       "            1.5259e-01,  4.3579e-01],\n",
       "          [ 7.2218e-01,  7.5730e-02,  8.8489e-01,  ...,  4.5814e-01,\n",
       "           -8.0805e-01,  2.1098e+00],\n",
       "          [-4.6366e-01,  9.8339e-01,  7.7649e-01,  ..., -1.1860e+00,\n",
       "            5.7387e-01, -1.9731e+00],\n",
       "          ...,\n",
       "          [ 1.1572e+00, -1.5657e+00,  3.6543e-01,  ...,  1.7056e+00,\n",
       "           -2.0972e+00,  7.4168e-01],\n",
       "          [ 1.3746e+00, -1.0905e+00,  1.4482e+00,  ..., -1.5076e+00,\n",
       "            6.7227e-01, -1.6922e+00],\n",
       "          [ 1.8828e+00, -1.6623e+00,  3.2881e-01,  ..., -5.9274e-01,\n",
       "           -1.7178e-01, -4.4942e-01]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sa0(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.68 s ± 95.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 ms ± 41.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original SelfAttention layer uses softmax on an N * N matrix, which I believe would be O(N^2) as well. since we do softmax N times and softmax is O(N) according to http://cs231n.stanford.edu/reports/2017/pdfs/130.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improved SimpleSelfAttention layer seems to provide a major improvement in terms of complexity compared to the original SelfAttention layer. It remains to be demonstrated whether it can work as an equivalent layer (e.g. in self-attention GANs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
